Sachin Natesh - Homework 4 Responses

------------------------------------#### Notes ####-------------------------------------------------------

- For comparing between graphics cards, I use my computer with an NVIDIA GeForce 1060 
  graphics card (1280 CUDA cores), and the cuda1/cuda2/cuda3 cims GPU nodes. 

- Timings for 2D Jacobi are conducted on my machine with 1000 iterations. 

- In all tests, the CPU time uses an OpenMP implementation with the thread count given by OMP_NUM_THREADS.

- I'm a CUDA noob and couldn't generalize parallel reduction with dot product to mat-vec without using
  dynamic parallelism features. The performance gains are only seen for large N, and are marginal.
  If N = NUM_BLOCKS = BLOCK_SIZE, there is a simple kernel that gives the same performance as dot product,
  but I have not included it in the code.

-------------------------#### Dot Product by parallel reduction N = 2^25 ####------------------------------

My Machine:
  CPU Bandwidth = 14.871513 GB/s
  GPU Bandwidth = 49.910513 GB/s
  Error = 0.000000

cuda1:
  CPU Bandwidth = 14.821633 GB/s
  GPU Bandwidth = 63.861873 GB/s
  Error = 0.000000

cuda2:
  CPU Bandwidth = 12.569415 GB/s
  GPU Bandwidth = 174.368624 GB/s
  Error = 0.000000

cuda3:
  CPU Bandwidth = 9.001908 GB/s
  GPU Bandwidth = 285.807727 GB/s
  Error = 0.000000

--------------------#### Matrix Vector Product by *attempted* parallel reduction N = 2^14 ####------------- 

My Machine:
  CPU Bandwidth = 23.643488 GB/s
  GPU Bandwidth = 36.818602 GB/s
  Error = 0.000000

cuda1:
  CPU Bandwidth = 20.612585 GB/s
  GPU Bandwidth = 30.044995 GB/s
  Error = 0.000000


cuda2:
  CPU Bandwidth = 23.889063 GB/s
  GPU Bandwidth = 78.382466 GB/s
  Error = 0.000000

cuda3 (using N = 2^12, terrible performance):
  CPU Bandwidth = 4.812445 GB/s
  GPU Bandwidth = 0.002560 GB/s
  Error = 0.000000


-------------------------------------#### 2D Jacobi for 1000 iterations ####------------------------------------------

  N         CPU (s)         GPU (s)         Speedup         Res CPU         Res GPU          Error
 30        0.491777        0.290348         1.69375     0.000152309     0.000152309      1.0328e-09
 40         2.36218        0.475859         4.96403      0.00104569      0.00104568      3.6171e-05
 50         6.61751        0.806993         8.20022       0.0023793       0.0023793     2.59668e-06
 60         14.3218         1.14023         12.5605      0.00352413      0.00352407     0.000750887
 70          32.052         1.77498         18.0577      0.00428672      0.00428671      0.00021534
 80         128.505         2.52671         50.8585      0.00471607      0.00471601      0.00161782
 90         118.214         3.69206         32.0186      0.00491151      0.00491149     0.000819344
100         218.968         5.35449         40.8943      0.00495763      0.00495761      0.00111736



------------------------------------#### Final project update ####--------------------------------

I've made decent progress on my final project. As a reminder, I am implementing spreading and
interpolation routines to couple forces on lagrangian particles to a uniform Eulerian grid using
a compactly supported spreading kernel. I haven't run into any issues yet. So far, I've implemented: 
 
  1) An array-based linked-list data structure based on open addressing. This structure partitions
     particles randomly distributed throughout the Eulerian grid into columns (as viewed from the top).
     An array firstn(i,j) gives p_ind, the first particle in column(i,j) of the grid. Then, another
     array nextn(p_ind) gives the next particle in column(i,j).
  2) Gather and scatter operations so that I can exploit auto-vectorization during the spreading
     and interpolation loops, parallelized over the columns in each group (separated by kernel width * h)

 
